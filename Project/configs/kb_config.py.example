import os

DEFAULT_KNOWLEDGE_BASE = "samples"
DEFAULT_VS_TYPE = "faiss"  # Set your default vector store type

CACHED_VS_NUM = 3
CACHED_MEMO_VS_NUM = 10
CHUNK_SIZE = 250
OVERLAP_SIZE = 50
VECTOR_SEARCH_TOP_K = 3
SCORE_THRESHOLD = 1.0
DEFAULT_SEARCH_ENGINE = "duckduckgo"
SEARCH_ENGINE_TOP_K = 3

BING_SEARCH_URL = "https://api.bing.microsoft.com/v7.0/search"
BING_SUBSCRIPTION_KEY = ""
METAPHOR_API_KEY = ""
SENIVERSE_API_KEY = ""
PDF_OCR_THRESHOLD = (0.6, 0.6)
KB_INFO = {
    "Knowledge Base Name": "Knowledge Base Introduction",
    "samples": "Answers to the issues of this project",
}

KB_ROOT_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "knowledge_base")
if not os.path.exists(KB_ROOT_PATH):
    os.mkdir(KB_ROOT_PATH)

DB_ROOT_PATH = os.path.join(KB_ROOT_PATH, "info.db")
SQLALCHEMY_DATABASE_URI = f"sqlite:///{DB_ROOT_PATH}"

kbs_config = {
    "faiss": {},
    "milvus": {
        "host": "0.0.0.0",
        "port": "19530",
        "user": "",
        "password": "",
        "secure": False,
    },
    "es": {
        "host": "0.0.0.0",
        "port": "9200",
        "index_name": "test_index",
        "user": "",
        "password": ""
    },
    "qdrant": {
        "host": "localhost",
        "port": "6333"
    },
    "chroma": {},
    "redis": {
        "host": "localhost",
        "port": "6379"
    }
}

text_splitter_dict = {
    "ChineseRecursiveTextSplitter": {
        "source": "Huggingface",
        "tokenizer_name_or_path": "models/all-MiniLM-L6-v2/tokenizer.json",
    },
    "SpacyTextSplitter": {
        "source": "huggingface",
        "tokenizer_name_or_path": "gpt2",
    },
    "RecursiveCharacterTextSplitter": {
        "source": "tiktoken",
        "tokenizer_name_or_path": "cl100k_base",
    },
    "MarkdownHeaderTextSplitter": {
        "headers_to_split_on": [
            ("#", "head1"),
            ("##", "head2"),
            ("###", "head3"),
            ("####", "head4"),
        ]
    },
}

TEXT_SPLITTER_NAME = "ChineseRecursiveTextSplitter"
EMBEDDING_KEYWORD_FILE = "embedding_keywords.txt"

embedding_model_config = {
    "model_name": "all-MiniLM-L6-v2",
    "path": "models/all-MiniLM-L6-v2/onnx/model_quantized.onnx",
    "config_path": "models/all-MiniLM-L6-v2/config.json",
    "tokenizer_path": "models/all-MiniLM-L6-v2/tokenizer.json",
}
